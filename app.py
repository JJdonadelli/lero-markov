import streamlit as st
import re
import random
from collections import defaultdict, Counter
import os

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Gerador de Texto Alice",
    page_icon="",
    layout="wide",
    initial_sidebar_state="expanded"
)

@st.cache_data
def ler_arquivos():
    """L√™ os dois arquivos de texto e retorna o conte√∫do combinado."""
    maravilha = ""
    espelho = ""
    
    if os.path.exists('data/maravilha-limpo.txt'):
        try:
            with open('data/maravilha-limpo.txt', 'r', encoding='utf-8') as f:
                maravilha = f.read()
        except Exception as e:
            st.error(f"Erro ao ler maravilha-limpo.txt: {e}")
    else:
        st.error("Arquivo 'data/maravilha-limpo.txt' n√£o encontrado!")
    
    if os.path.exists('data/espelho-limpo.txt'):
        try:
            with open('data/espelho-limpo.txt', 'r', encoding='utf-8') as f:
                espelho = f.read()
        except Exception as e:
            st.error(f"Erro ao ler espelho-limpo.txt: {e}")
    else:
        st.error("Arquivo 'data/espelho-limpo.txt' n√£o encontrado!")
    
    return maravilha + " " + espelho

@st.cache_data
def preprocessar_texto(texto):
    """Preprocessa o texto removendo caracteres especiais e convertendo para min√∫sculas."""
    if not texto:
        return ""
    
    # Remove quebras de linha excessivas e caracteres especiais
    texto = re.sub(r'\n+', ' ', texto)
    texto = re.sub(r'[^\w\s\.\!\?\,\;\:]', '', texto)
    
    # Converte para min√∫sculas
    texto = texto.lower()
    
    # Remove espa√ßos m√∫ltiplos
    texto = re.sub(r'\s+', ' ', texto)
    
    return texto.strip()

@st.cache_data
def tokenizar(texto):
    """Tokeniza o texto em palavras."""
    tokens = [token for token in texto.split() if token]
    return tokens

@st.cache_data
def criar_ngramas(tokens, n):
    """Cria um dicion√°rio de n-gramas a partir dos tokens."""
    ngramas = defaultdict(list)
    
    for i in range(len(tokens) - n + 1):
        # Chave: n-1 palavras anteriores
        chave = tuple(tokens[i:i+n-1])
        # Valor: pr√≥xima palavra
        proxima_palavra = tokens[i+n-1]
        ngramas[chave].append(proxima_palavra)
    
    return dict(ngramas)

@st.cache_data
def encontrar_palavras_interessantes(tokens):
    """Encontra palavras interessantes e relevantes para come√ßar o texto."""
    palavras_alice = [
        'alice', 'coelho', 'chapeleiro', 'gato', 'rainha', 'rei', 'carta', 'cartas',
        'ch√°', 'mesa', 'jardim', 'buraco', 'toca', 'rel√≥gio', 'tempo', 'mundo',
        'pa√≠s', 'maravilhas', 'espelho', 'sonho', 'dormindo', 'acordar',
        'pequena', 'grande', 'crescer', 'diminuir', 'po√ß√£o', 'beber', 'comer',
        'porta', 'chave', 'curiosa', 'estranha', 'estranho', 'medo', 'coragem'
    ]
    
    contador = Counter(tokens)
    
    palavras_disponiveis = []
    for palavra in palavras_alice:
        if palavra in contador and contador[palavra] > 3:
            palavras_disponiveis.append(palavra)
    
    palavras_frequentes = [palavra for palavra, freq in contador.most_common(30) 
                          if len(palavra) > 3 and palavra.isalpha()]
    
    todas_palavras = list(set(palavras_disponiveis + palavras_frequentes[:15]))
    
    return sorted(todas_palavras)

def gerar_texto(ngramas_dict, palavra_inicial, n, tamanho=51):
    """Gera texto usando cadeias de Markov com n-gramas progressivos."""
    resultado = [palavra_inicial]
    
    for tamanho_atual in range(2, n + 1):
        if len(resultado) >= tamanho:
            break
            
        ngramas_atuais = ngramas_dict[tamanho_atual]
        contexto_size = tamanho_atual - 1
        
        tentativas = 0
        max_tentativas = 100
        
        while len(resultado) < tamanho and tentativas < max_tentativas:
            tentativas += 1
            
            if len(resultado) < contexto_size:
                break
                
            contexto = tuple(resultado[-contexto_size:])
            
            if contexto in ngramas_atuais and ngramas_atuais[contexto]:
                proxima = random.choice(ngramas_atuais[contexto])
                resultado.append(proxima)
                tentativas = 0  # Reset tentativas quando encontra uma palavra
            else:
                if contexto_size > 1:
                    contexto_menor = contexto[1:]
                    if contexto_menor in ngramas_atuais and ngramas_atuais[contexto_menor]:
                        proxima = random.choice(ngramas_atuais[contexto_menor])
                        resultado.append(proxima)
                        tentativas = 0
                    else:
                        break
                else:
                    break
    
    return resultado[:tamanho]

def adicionar_pontuacao_basica(texto):
    """Adiciona pontua√ß√£o b√°sica ao texto gerado."""
    palavras = texto.split()
    resultado = []
    
    for i, palavra in enumerate(palavras):
        resultado.append(palavra)
        
        # Ponto a cada 10-15 palavras aproximadamente
        if (i + 1) % random.randint(10, 15) == 0 and i < len(palavras) - 1:
            resultado[-1] += '.'
    
    return ' '.join(resultado)

def main():
    # T√≠tulo principal
    st.title("Gerador de Lero-lero com Cadeias de Markov")
    # st.markdown("### *Baseado nos livros de Alice no Pa√≠s das Maravilhas*")
    
    # Sidebar para configura√ß√µes
    with st.sidebar:
        st.header("‚öôÔ∏è Configura√ß√µes")
        
        # Par√¢metro N
        n = st.slider(
            "Ordem dos N-gramas (n)",
            min_value=2,
            max_value=6,
            value=3,
            help="Ordem dos n-gramas. Valores maiores geram texto mais coerente mas menos criativo."
        )
        
        # Tamanho do texto
        tamanho = st.number_input(
            "Tamanho do texto (palavras)",
            min_value=10,
            max_value=200,
            value=51,
            help="N√∫mero de palavras a serem geradas."
        )
        
        st.divider()
        
        # Informa√ß√µes
        st.markdown("""
        ### Como funciona?
        O algoritmo aprende padr√µes de palavras consecutivas atrav√©s das est√≥rias de Alice, de Lewis Carrol. 
        
        ### Dica:
        - N baixo = mais criativo, menos coerente
        - N alto = mais coerente, menos criativo
        """)
    
    # Carrega e processa os dados
    if 'texto_processado' not in st.session_state:
        with st.spinner("Carregando e processando os livros da Alice..."):
            texto_completo = ler_arquivos()
            
            if not texto_completo.strip():
                st.error("N√£o foi poss√≠vel carregar os arquivos de texto!")
                st.stop()
            
            texto_limpo = preprocessar_texto(texto_completo)
            tokens = tokenizar(texto_limpo)
            
            st.session_state.texto_processado = True
            st.session_state.tokens = tokens
            st.session_state.palavras_interessantes = encontrar_palavras_interessantes(tokens)
    
    
    
    st.divider()
    
    # Sele√ß√£o da palavra inicial
    st.header(" Escolha da Palavra Inicial")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        # Selectbox com palavras interessantes
        palavra_selecionada = st.selectbox(
            "Palavras sugeridas (relacionadas √†s f√°bulas):",
            options=st.session_state.palavras_interessantes,
            help="Palavras extra√≠das automaticamente dos textos da Alice"
        )
    
    with col2:
        # Input manual
        palavra_manual = st.text_input(
            "Ou digite uma palavra:",
            placeholder="ex: gato",
            help="Digite qualquer palavra para come√ßar o texto"
        )
    
    # Determina a palavra inicial
    palavra_inicial = palavra_manual.lower().strip() if palavra_manual else palavra_selecionada
    
    # Bot√£o para gerar texto
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        gerar_button = st.button(
            "üé≤ Gerar Texto",
            type="primary",
            use_container_width=True
        )
    
    # Gera√ß√£o do texto
    if gerar_button:
        if not palavra_inicial:
            st.error("Por favor, selecione ou digite uma palavra inicial!")
        else:
            with st.spinner(f"Gerando texto com {n}-gramas..."):
                # Cria n-gramas
                ngramas_dict = {}
                progress_bar = st.progress(0)
                
                for i, tamanho_atual in enumerate(range(2, n + 1)):
                    ngramas_dict[tamanho_atual] = criar_ngramas(st.session_state.tokens, tamanho_atual)
                    progress_bar.progress((i + 1) / (n - 1))
                
                progress_bar.empty()
                
                # Gera o texto
                texto_gerado = gerar_texto(ngramas_dict, palavra_inicial, n, tamanho)
                
                # Exibe o resultado
                st.success("‚ú® Texto gerado com sucesso!")
                
                # Container para o texto gerado
                st.header("üìñ Texto Gerado")
                
                texto_final = ' '.join(texto_gerado)
                # texto_final = adicionar_pontuacao_basica(texto_final_pre)

                # Caixa de texto com o resultado
                st.text_area(
                    "Resultado:",
                    value=texto_final,
                    height=200,
                    help="Texto gerado usando cadeias de Markov"
                )
                
                # Estat√≠sticas da gera√ß√£o
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("üìù Palavras Geradas", len(texto_gerado))
                with col2:
                    st.metric("üîß N-gramas Usados", n)
                with col3:
                    st.metric("üéØ Palavra Inicial", f'"{palavra_inicial}"')
                with col4:
                    st.metric("üìä Caracteres", len(texto_final))
                
                # Op√ß√£o de download
                st.download_button(
                    label="üíæ Baixar Texto",
                    data=texto_final,
                    file_name=f"alice_texto_gerado_{n}gramas.txt",
                    mime="text/plain"
                )
                
                # Exibe algumas estat√≠sticas dos n-gramas
                with st.expander("üîç Estat√≠sticas Detalhadas"):
                    for i in range(2, n + 1):
                        st.write(f"**{i}-gramas**: {len(ngramas_dict[i]):,} combina√ß√µes √∫nicas")
                    
                    # Mostra algumas palavras mais frequentes
                    contador = Counter(st.session_state.tokens)
                    palavras_freq = contador.most_common(10)
                    
                    st.write("**Palavras mais frequentes no corpus:**")
                    freq_text = ", ".join([f"{palavra} ({freq})" for palavra, freq in palavras_freq])
                    st.write(freq_text)
    
    # Hist√≥ria de Markov no final da p√°gina
    st.divider()
# Estat√≠sticas do corpus
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("üìö Total de Palavras", f"{len(st.session_state.tokens):,}")
    with col2:
        st.metric("üî§ Palavras √önicas", f"{len(set(st.session_state.tokens)):,}")
    with col3:
        palavras_alice = len([p for p in st.session_state.palavras_interessantes 
                             if p in ['alice', 'coelho', 'chapeleiro', 'gato', 'rainha']])
        st.metric("üé≠ Palavras da Alice", palavras_alice)

    st.divider()

    st.header("A hist√≥ria")
    
    st.markdown("""
    
    As **Cadeias de Markov** recebem o nome do matem√°tico russo **Andrei Andreevich Markov** (1856-1922), que desenvolveu 
    essa teoria no in√≠cio do s√©culo XX. Markov era professor na Universidade de S√£o Petersburgo e um dos 
    principais matem√°ticos de sua √©poca. 
      
    Curiosamente, o primeiro experimento famoso de Markov com sua pr√≥pria teoria foi realizado em **1913** 
    usando o romance √©pico russo **"Eugene Onegin"** de Alexander Pushkin! Markov analisou a sequ√™ncia de 
    vogais e consoantes no texto para demonstrar como eventos futuros podiam depender apenas do estado presente, 
    n√£o de toda a hist√≥ria anterior.
    
    A **propriedade markoviana** estabelece que:
    > *"O futuro depende apenas do presente, n√£o do passado"*
    
    Em termos matem√°ticos, isso significa que a probabilidade do pr√≥ximo estado depende apenas do estado atual, 
    n√£o de como chegamos at√© ele. No contexto de gera√ß√£o de texto:
    - A pr√≥xima palavra depende apenas das √∫ltimas N-1 palavras
    - N√£o importa todo o hist√≥rico anterior do texto
       
    Hoje, as Cadeias de Markov s√£o fundamentais em:
    - **Processamento de Linguagem Natural** (como este aplicativo!)
    - **An√°lise Financeira** (modelagem de pre√ßos de a√ß√µes)
    - **Bioinform√°tica** (an√°lise de sequ√™ncias de DNA)
    - **Intelig√™ncia Artificial** (chatbots e sistemas de recomenda√ß√£o)
    """)
    
    # Cr√©ditos
    st.markdown("""
    ---
    **Desenvolvido em Streamlit**  
    """)

if __name__ == "__main__":
    main()
